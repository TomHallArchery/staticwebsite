---
author: tomhall2016
categories:
- Equipment Reviews
comments: true
date: 2018-05-14 19:30:17
date_created: 2021-12-21 00:00:00
keywords: []
layout: post
link: https://tomhall2016.wordpress.com/2018/05/14/on-test-easton-vs-cx/
slug: on-test-easton-vs-cx
tags:
- Arrows
- Equipment
- Training Camp
title: 'On Test: Easton vs Carbon Express'
wordpress_id: 1452
---

Arrows are the single most important piece of equipment any archer can get. We often get distracted thinking about all the ways our riser, limbs, string, stabilisation etc. can affect the consistency of our shooting, but at the end of the day you'll be using the same kit for every shot of a scoring round. But with arrows, every end you are shooting a different missile and hoping they will group together. This is where there are the most variables and therefore a huge advantage in getting the most consistent set possible.

For many people this justifies stretching to a high end set of arrows, and make no mistake its frighteningly easy to drop Â£500 on a full set. This makes it very expensive to try different makes and brands, even before you worry about choosing the correct spine! Recently I've been testing two premium models of arrow for target archery, read on to find out my results....


## Easton X10 vs Carbon Express Nano-Pro Extreme


Since 2013 I've been shooting the same make of arrow for all of my competitive archery,  X10s. This barrelled aluminium/carbon design has been THE standard for about two decades and they have an indisputable track record of international success. My most recent set was built in early 2017 and has been used only for competitions and tuning, since I have an older set to use for general practice.

To test against them I have been able to borrow a set of Carbon Express Nano-Pro Extremes, taken from Patrick Huston's Olympic set in 2016. These are a parallel, all-carbon design which have three different stiffness "zones" along the arrow, with the stiffest part in the centre. The 12 arrows I have were sorted out from a 4 dozen batch taken for testing at the Beiter centre, where Patrick used the best matched 24 arrows at Rio and left the remainder; these are the better 12 of that remainder.

To complete the arrows, I've used 110 gn points (tungsten/tool-steel),  pins, Easton Pin nocks (large), and P3 Elivanes on both sets.

[gallery ids="1458,1457" type="square" columns="2"]


## The Data


Some comparisons can be done without a bow, at the workbench. The three key features to look for in a quality set of arrows are consistency in weight, straightness, and spine. At Lilleshall I had the equipment to test for weight and spine, and these are the results.

<table cellpadding="0" width="679" cellspacing="0" border="1" >
<tbody >
<tr >

<td colspan="1" rowspan="1" >
</td>

<td colspan="1" rowspan="1" >X10-450
</td>

<td colspan="1" rowspan="1" >NPX-450
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >Shaft Length /mm
</td>

<td colspan="1" rowspan="1" >720
</td>

<td colspan="1" rowspan="1" >747
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >Measured Spine (Avg)
</td>

<td colspan="1" rowspan="1" >459
</td>

<td colspan="1" rowspan="1" >447
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >Weight (Avg) /gn
</td>

<td colspan="1" rowspan="1" >362.5
</td>

<td colspan="1" rowspan="1" >359.7
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >Weight Range /gn
</td>

<td colspan="1" rowspan="1" >1
</td>

<td colspan="1" rowspan="1" >1
</td>
</tr>
</tbody>
</table>
Both sets of arrows, when fully built up, could be matched to within 1 grain weight range across the set. For the same "Spine" of arrow, the true static spine of the Nanos is stiffer by about 12 thousandths of an inch compared to the X10s. This partly explains why I had to cut them longer, so that they will both spine correctly at the same draw weight, between 45-47 lbs depending which bow I use, although the X10s are clearly dynamically a bit softer. Even with this extra length the Nanos are slightly lighter by about three grains per arrow.

![SpineDeviation (1)](https://tomhall2016.files.wordpress.com/2018/04/spinedeviation-1.png)

With the spine tester I measured the spine of each arrow three times at 120 degree intervals, giving 36 spine readings per 12 arrow set. I've subtracted the average spine per arrow set from each of these readings to give the data for the boxplot above. Both sets have similar variation though the range of spines in the Nanos is less, between +/- 5 units instead of +/- 7 for the X10s.


## Testing in the field


Numbers are nice to look at but at the end of the day the only numbers that really matter are those written on the scoresheet. To test this I've used aggregated plotting; recording every scoring arrow shot at 70m over an extended time period and combining the results.

Testing in this way has a few advantages. It allows me to combine more data than I could do in a single testing session, it makes sure that I shoot both sets in varied conditions (indoors, calm outdoors and in wind), and that the result does not depend on me having a "good day" with one set and not the other. Finally it makes sure I get to test them shooting under match conditions, since I have included scoring from squad training days, training camps and competitions.

To aggregate all the data I used Artemis, which is the only app I know of that allowed me to plot multiple rounds over a 2 month period and then combine all of the results into a single plot. You have to upgrade to the paid version to be able to do this but being able to do arrow testing in such a comprehensive way makes it well worth the cost of half a dozen nocks!


## The results


The first place to start is the aggregated plot for each arrow type. These arrows were shot between February and March in 2017. Artemis gives an "Archers Skill Rating" that takes into account distance, face size and group size and shape.

![Screenshot_2018-04-18-12-24-55](https://tomhall2016.files.wordpress.com/2018/04/screenshot_2018-04-18-12-24-55.png)

Firstly, both groups are reasonably centred on the 10, as you would hope over hundreds of arrows shot in competitive conditions! This means we can use score as an indicator of performance without worrying that the results will be biased by one group being off centre. Its immediately apparent that the group for the Nanos is a bit tighter, having hit no blues and receiving a higher skill rating from Artemis.

I then dug a little deeper, calculating the total number of arrows within each scoring ring for both sets of arrows, and therefore the % of the total that falls within each scoring ring.

<table cellpadding="0" cellspacing="0" border="1" dir="ltr" >
<tbody >
<tr >

<td colspan="1" rowspan="1" >
</td>

<td colspan="1" rowspan="1" >NPX (%)
</td>

<td colspan="1" rowspan="1" >X10 (%)
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >X
</td>

<td colspan="1" rowspan="1" >79 (10.5)
</td>

<td colspan="1" rowspan="1" >43 (8.0)
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >10
</td>

<td colspan="1" rowspan="1" >142 (19.0)
</td>

<td colspan="1" rowspan="1" >108 (20.1)
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >9
</td>

<td colspan="1" rowspan="1" >348 (46.5)
</td>

<td colspan="1" rowspan="1" >243 (45.2)
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >8
</td>

<td colspan="1" rowspan="1" >150 (20.0)
</td>

<td colspan="1" rowspan="1" >105 (19.5)
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >7
</td>

<td colspan="1" rowspan="1" >30 (4.0)
</td>

<td colspan="1" rowspan="1" >33 (6.1)
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >6
</td>

<td colspan="1" rowspan="1" >0 (0)
</td>

<td colspan="1" rowspan="1" >5 (0.9)
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" >5
</td>

<td colspan="1" rowspan="1" >0 (0)
</td>

<td colspan="1" rowspan="1" >1 (0.2)
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" > Total
</td>

<td colspan="1" rowspan="1" >749
</td>

<td colspan="1" rowspan="1" >538
</td>
</tr>
<tr >

<td colspan="1" rowspan="1" > Average
</td>

<td colspan="1" rowspan="1" >9.01
</td>

<td colspan="1" rowspan="1" >8.93
</td>
</tr>
</tbody>
</table>
So we have a higher relative probability of scoring X, 9 or 8 with the Nanos comapred to the X10s which gain more 10s, but also more 7s, 6s and 5s. The average score per arrow is 0.08 points higher for the Nanos, which equates to an average of about 6 points per 72 arrow ranking round.


## Conclusions


I don't think there's many people who would turn down an extra 6 points on their score, and I'm not one of them. Having done this testing over a long period now, subjectively I've begun to trust the Nanos just a little bit more, finding it easier to keep the group centred and feeling that good shots are rewarded with Xs and 10s more often. I did not observe much difference in wind drift, which makes sense as both arrows are similar in diameter and weight.

I found myself choosing to use the Nanos in high pressure events such as the spring arrows international tournament in Turkey, where I picked up team Bronze and came 5th individually. More recently I used them to set a new PB at 70m of 675, and having that extra bit of confidence in my kit definitely helped!

![20180506_164420_HDR.jpg](https://tomhall2016.files.wordpress.com/2018/05/20180506_164420_hdr.jpg)

Yes this testing has its limitations; neither set of arrows was "out of the box" new for a start. More seriously, I could not blind test them, I was always aware of what arrow I was shooting. While for the first 300 arrows or so with each I was not sure if there was a clear difference, once something started to emerge out of the data then its highly likely that this would have influenced me.

For me though, this test shows that it's always worth trying new things. As a result of this I'll be continuing to use the Carbon Express arrows for the rest of the season. Of course there's always more work to do, and the next stage of testing is plotting of individual arrow numbers to select the best grouping shafts from within a set, but that's a post for another time!